https://t.co/uu79gVNlAx
A Start-to-Finish Guide to Building Deep Neural Networks in Keras Sign in Data Science Machine Learning Programming Visualization AI Video About Contribute A Start-to-Finish Guide to Building Deep Neural Networks in Keras Everything from image augmentation to plotting accuracy Andre Ye Follow Mar 27 · 5 min read Learning deep learning is daunting; so libraries like Keras that make it easy are helpful. In this article, I outline, explain, and provide code for 7 steps in building an image recognition deep convolutional neural network in Keras. 1 | Loading Image Data and Basic Preprocessing Images will (most of the time) be in a .png or .jpg format. They can be loaded using the cv2 library with image = cv2.imread(file_directory). The cv2 library has handy exporting from a cv2 image to a numpy array, done through img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB). This will yield an array of dimensions (m, n, 3), where m and n are the dimensions of the image. 3 is representative of the depth, or the amount of red, green, and blue to incorporate for the final pixel color. Extracting the numerical data from an image. Finally, the data should be scaled, or put on a scale from between 0 to 1. This improves model performance (mathematically, neural networks operate better on a 0-to-1 scale). This can be done with x /= 255. When all the data is collected, it should be in a array of dimension (x, m, n, 3) where x is the number of samples in your dataset. If the y value is categorical, it can be easily one-hot encoded with Keras’ to_categorical: from keras.utils import to_categorical y = to_categorical(y) 2 | Splitting into training and testing For this step, we’ll use sklearn’s tool for splitting the data into training and testing sets. You can substitute the test_size with whatever size you want to use — this is a balance between not having enough training data to properly train on against not having enough testing data to properly evaluate the model’s performance on new data. from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) 3 | Data Augmentation with ImageDataGenerator Often, using data augmentation to slightly change the image can help a deep neural network model learn more from the dataset and generalize better. from keras.preprocessing.image import ImageDataGenerator This imports the ImageDataGenerator object. Now, it can be initialized with parameters on how the image should be augmented (how you control your parameters is a measure on the context. For example, an image to be augmented for facial recognition should be more on the conservative side with drastic distortion effects). datagen = ImageDataGenerator(      featurewise_center=True,      featurewise_std_normalization=True,      rotation_range=20,      width_shift_range=0.2,      height_shift_range=0.2,      horizontal_flip=True) The data generator can be fitted with datagen.fit(X_train) Finally (skipping ahead a bit), during training, the model can be trained on datagen.flow(), which is a Keras iterator that provides augmented images directly to the model. model.fit_generator(datagen.flow(X_train, y_train, batch_size=size),                     steps_per_epoch=len(X_train) / size, epochs=epochs) Example of augmented images from Keras’ ImageDataGenerator. 4 | Building the Model Architecture All Keras models begin with their initialization: from keras.models import Sequential model = Sequential() From here, it is possible to add new layers easily with model.add(): from keras.layers import Conv2D model.add(Conv2D(32, (5, 5), input_shape=(150, 150, 3)) Every first layer in a model, no matter what type, must have a parameter input_shape that tells the model the shape of the image. In this case, input_shape should be substituted with whatever shape of image you are working with. For a complete guide to Keras layers and what they do, check out this article. Most convolutional neural network architectures consist of several cells, which usually consist of a convolutional layer, a pooling layer, an activation layer, and a dropout layer: model.add(Conv2D(32, (5,5)) model.add(MaxPooling2D(pool_size=(2,2)) model.add(Activation('relu')) model.add(Dropout(0.25)) However, cells can be alternating in layer (perhaps odd cells only comprise of convolutional, pooling, and activation layers, and even cells comprised of convolutional, pooling, and dropout layers). After a few generalization cells, the data is usually flattened from a two-dimensional array into a one-dimensional array and passed through Dense layers (standard artificial neural network layers). How the model architecture is chosen is a matter of the dataset context. For a more specific understanding of the number of parameters and shape of inputs passed per layer, model.summary() prints out the total number of parameters and shape of the data as it passes through the image to help guide making architecture decisions based on training time. model.summary() example output 5 | Compile the model After the model architecture is specified, the model must be compiled with an optimizer and a loss function. There’s also an option to specify metrics that can be plotted later. model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['mae','mse'] For a resource on different types of model optimizers and how to choose them, click here. An article on what loss functions to choose can be found here as well. Adam is a common optimizer used and should be the default if not training a neural network for especially import purposes. The loss function is also usually cross entropy, which comes in many forms — categorical cross entropy for categorical y values, binary cross entropy for binary y values, and sparse categorical cross entropy for categorical y values with a large number of classes. 6 | Fitting the Model Fitting the model is simple. The X_train and y_train training sets, as well as the validation split (how much of the X_train is taken each epoch to measure how well the model generalizes on unseen data), the number of epochs (the number of times the model goes over the entire dataset), and the batch size (how may training examples are processed at a time), need to be specified. history = model.fit(X_train, y_train, validation_split=0.25, epochs=50, batch_size=16) If you used the image augmentation, training would be model.fit_generator(datagen.flow(X_train, y_train, batch_size=size),                     steps_per_epoch=len(X_train) / size, epochs=50) By saving it to history, we can plot its metrics over time. 7 | Plotting model progress during training The history is saved into the variable history, whose data can be extracted through history.history[metric]. Whatever metrics you included when the model was compiled can be accessed as well as included ones, like loss. plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) plt.title('Model Loss') plt.ylabel('Loss') plt.xlabel('Epochs') plt.legend(['Train', 'Test'], loc='upper right') plt.show() Thanks for reading! The model isn’t fully completed — it needs an interface! Truly finish off the model by building an interactive image-taking interface to use your model here. Towards Data Science A Medium publication sharing concepts, ideas, and codes. Follow 37 Keras Neural Networks AI Machine Learning Data Science 37 claps Written by Andre Ye Follow Inspired by AI, driven by data. — — https://www.linkedin.com/in/andre-ye-501746150/ Follow Towards Data Science Follow A Medium publication sharing concepts, ideas, and codes. Follow Write the first response More From Medium More from Towards Data Science More from Towards Data Science from sklearn import * Conor Lazarou in Towards Data Science Mar 22 · 9 min read 2.5K More from Towards Data Science More from Towards Data Science Top 3 Python Functions You Don’t Know About (Probably) Dario Rade?i? in Towards Data Science Mar 14 · 4 min read 4.3K More from Towards Data Science More from Towards Data Science Don’t learn machine learning Caleb Kaiser in Towards Data Science Mar 19 · 4 min read 2.4K Discover MediumWelcome to a place where words matter. On Medium, smart voices and original ideas take center stage - with no ads in sight. Watch Make Medium yoursFollow all the topics you care about, and we’ll deliver the best stories for you to your homepage and inbox. Explore Become a memberGet unlimited access to the best stories on Medium — and support writers while you’re at it. Just $5/month. Upgrade AboutHelpLegal
