https://towardsdatascience.com/power-up-your-python-projects-with-visual-studio-code-401f78dd97eb?source=user_profile---------5-----------------------#--responses
Power up your Python Projects with Visual Studio Code Sign in Data Science Machine Learning Programming Visualization AI Video About Contribute Power up your Python Projects with Visual Studio Code Set up nearly-automatic Python virtual environments and create Jupyter notebooks and more in Visual Studio Code. Lora Johns Follow Dec 7, 2019 · 7 min read Why use virtual environments in data science? We know the importance of dependency management for package development and software developers. But what about for people doing data science who aren’t deploying to PyPI or conda-forge? Virtual environments can help you fix things when they break. If you’ve been using Python for any length of time, you’ve had the frustration of a cluttered development environment with too many packages installed. You don’t need them all at one time, and trying to figure out which ones are necessary for your project is frustrating to do by hand. Packages don’t always get upgraded at the same time, and many are not compatible with each other or even with the version of Python or Anaconda that you’re running. Packages from the different channels within conda aren’t even guaranteed not to conflict. If you’re downloading everything into the same big environment, it’s inevitable that you’ll end up with inconsistent dependencies, and things will break. this is not wise. Not to mention the various tools like pip, pipx, conda, poetry, hatch, pipenv, pyenv, virtualenv, pyvenv, pyenv-virtualenv, virtualenvwrapper, pyenv-virtualenvwrapper, and venv… which, despite sounding very much alike, often aren’t even compatible with each other. If you use Anaconda, it’s a matter of when your project will break, not if. Further reason not to use anaconda outside of a container — you don’t know what you’re running. In some bizarre cases, anaconda’s activation script so badly mangles the system’s environment pre-pyenv cleanup that the only quick way to fix the problem is to prepend HOST=$(hostname) to the .zshrc. I feel confident running this code in my user root directory, don’t you? Virtual environments aid reproducibility in data science. Python has a fantastic open source community, but that also means a proliferation of tools and methods for everything. If you provide the exact versions of the libraries that you used in your scientific analysis, your results will be more verifiable. In fact, this dependency management can play a vital role in accountability and accuracy. Sometimes, errors in Python packages have been shown to be the root cause of computational errors in statistical models. It’s important to be able to trace whether you’ve used the erroneous packages so that you can verify or correct your results when necessary. Being able to freeze your requirements — and only those packages that are really requirements — for a given project, and provide it as an environment file for future reference, makes you a better collaborator and a better scientist. You’ll know exactly what your models used, when, and why. Using pyenv with pyenv-virtualenv lets you manage python installations safely I’ve written a (totally not comprehensive, guaranteed to break) guide to setting up your system with pyenv and pyenv-virtualenv here. It’s my favorite way to manage multiple installations, though because it’s: clean, flexible, and reversible resistant to user error a good safeguard against anaconda screwing up my environments If you don’t want to read the whole thing, I’ve distilled it into a cheat sheet here: lorarjohns/awesomeVenvs install and run the Anaconda uninstaller conda install anaconda-clean && anaconda-clean --yes find leftover directories… github.com I also use Arq Cloud Backup, which works similarly to git, and is pretty cheap and nearly automated, to protect important files before setting up a new system with this method. For Zotero, dotfiles, and smaller files I want more direct access to, I use Sync (essentially an end-to-end encrypted, GDPR-compliant Dropbox). An integrated development environment with pyenv and Visual Studio Code Once you have your pyenv installation set up, you create some really cool workflows for data science development in virtual environments. Let’s walk through creating a project with an Anaconda distribution to see how you can use Visual Studio Code to develop Jupyter notebooks and convert them to .py scripts. You should have a directory for every project, and a virtual environment for every directory. This structure does two important things: It keeps your stuff organized appropriately, which makes it easier to keep projects separate, manage dependencies, and keep out things that shouldn’t be there. (Who likes having to undo git commits?) It lets you create a separate .python-version file for each directory (and therefore for each project), which means pyenv-virtualenv can automatically switch to the appropriate environment for you when you change directories. Here’s the TL;DR version of project setup: Make a project folder and cd into it Set your project Python with pyenv local $PYTHON_VERSION Run this command (e.g.) to make a virtual environment: pyenv virtualenv anaconda3–2019.10 venv-cool_project If you leave out the Python version, your environment will use the one that is currently in effect locally. Activate your new environment and set it as the project’s local Python by executing pyenv local with the venv’s name, and activate the environment with (e.g.) conda activate venv-cool_project If you run the one-liner below every time you create a new project, you should be able to cd in and out of directories and have your virtual environments automatically activate and deactivate. (Of course, you’ll need to change the environment name and Python interpreter.) $ mkdir $2 && cd $2 && pyenv local $1 && pyenv virtualenv venv-$2 && pyenv local venv-$2 && pyenv activate venv-$2 Here’s a GitHub gist with a script that will do it for you. Download it (you may need to run chmod +x newproj.sh to make sure it’s executable). Then just use it to create new projects by passing it the python version you want to use and the name of your project: now you really have no excuse not to use venvs. Using Visual Studio Code with Python and Jupyter Visual Studio Code can do a lot of cool tricks. For one, it can automatically select the right virtual interpreter for your project directory, if you set things up according to the instructions above. To get started, brew cask install visual-studio-code. Then, go into VS Code’s settings: Make sure your system’s terminal is synced up with the application’s: tell VS Code to use your OS’s terminal application with the “External” variable. Turn on the integrated Terminal feature that lets you use a terminal emulator inside the VSCode app. VS Code user settings for integrated terminal and iTerm.app on macOS open the command palette with?+?+P and select Shell Command: Install 'code' command in PATH. This lets you launch VS Code from an external Terminal: code -- launches the app, code . opens the current working directory, and code path/to/file/or/dir opens a specific file or directory. one of my project directories, with an integrated terminal Install the Python extension for VS Code. Once enabled, as long as you’ve saved a file with a python extension, the editor will know it’s supposed to be interpreted in a Python context. You’ll notice that when you cd in and out of project directories in the integrated terminal, the python interpreter will automatically detect your venvs, as long as there is a .python-version file present (which there should be, if you used pyenv-virtualenv correctly). The name of the detected virtual environment, in the lower left-hand corner You can also explicitly tell the app which Python interpreter to use by clicking on the name of the Python interpreter in the bottom toolbar or by opening the command palette and typing Python: Select Interpreter. A list of available interpreters/environments and their paths Because we’re in a terminal, we can also create and activate new venvs as we normally do from here. Creating Jupyter notebooks To use notebooks, just open an .ipynb file or select Python: Create New Blank Jupyter Notebook from the command palette while inside a conda environment. You can then run cells and create notebooks as normal, but with the added benefit that you’re not dependent on your web browser. a jupyter notebook in a conda virtual environment in vscode You can also quickly convert a notebook to a Python script with one click, or with Python: Convert to python script: notebook converted to a script This is really handy for turning exploratory analyses into runnable, reproducible programs. Make great projects with confidence Now, when you start a project, you’ll be able to control the packages in your development environment, turn your conda envs into requirements.txt files with ease, and clean up your notebooks into production-worthy scripts much more efficiently. VS Code offers even more tools, like syntax highlighting, code linting, test integration, and interfaces with GitHub, Docker, various databases, and more, to power up your projects. Add these tools to your data science workflow to be a more effective programmer and developer. Towards Data Science A Medium publication sharing concepts, ideas, and codes. Follow 549 Python Data Science Programming Machine Learning Development 549 claps Written by Lora Johns Follow Machine learning, linguistics, NLP | { B.A. : Dartmouth, J.D. : Yale, M.S. : Simmons } Follow Towards Data Science Follow A Medium publication sharing concepts, ideas, and codes. Follow See responses (3) More From Medium More from Towards Data Science More from Towards Data Science from sklearn import * Conor Lazarou in Towards Data Science Mar 22 · 9 min read 2.5K More from Towards Data Science More from Towards Data Science Top 3 Python Functions You Don’t Know About (Probably) Dario Rade?i? in Towards Data Science Mar 14 · 4 min read 4.3K More from Towards Data Science More from Towards Data Science Don’t learn machine learning Caleb Kaiser in Towards Data Science Mar 19 · 4 min read 2.4K Discover MediumWelcome to a place where words matter. On Medium, smart voices and original ideas take center stage - with no ads in sight. Watch Make Medium yoursFollow all the topics you care about, and we’ll deliver the best stories for you to your homepage and inbox. Explore Become a memberGet unlimited access to the best stories on Medium — and support writers while you’re at it. Just $5/month. Upgrade AboutHelpLegal
