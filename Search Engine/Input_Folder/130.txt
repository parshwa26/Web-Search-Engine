https://towardsdatascience.com/beeralytics-a-guide-to-analyzing-beer-prices-from-web-data-37d4ba206071?source=collection_category---4------2-----------------------
Beeralytics — A Guide to Analyzing Beer Prices from Web Data Sign in Data Science Machine Learning Programming Visualization AI Video About Contribute Beeralytics — A Guide to Analyzing Beer Prices from Web Data Using Bokeh to find the best priced Beers on Delivery Sites Matt Grierson Follow Mar 23 · 14 min read Photo by Alban Martel on Unsplash A few weeks ago my girlfriend and I were having drinks at a bar and started debating what the cheapest beer on the menu was. The challenge itself was that there were multiple sizes and alcohol content across 20-or-so beers which made simple comparisons a challenge. Bets were made, and we started doing cell phone math (I swear we’re this exciting all the time) using a basic formula to normalize them: ‘Oz. of alcohol per $’ = ((‘Total Oz.’ * ‘Alcohol %’) / 100) / Price This revealed that the high ABV IPAs were the most value for your money by a decent margin! Now that I had lost yet another betting game to my girlfriend I was curious as to whether this was a local choice (maybe the bar had trouble moving those kinds of drinks) or was this kind of pricing consistent at scale? This seemed like a fun data science problem, so I started brainstorming ways in which to answer this question. A decade ago, this probably wouldn’t be possible without proprietary datasets or visiting each individual store and writing down all the pricing (I’m sure store owners love that). Instead we now have a plethora of delivery services like Drizly and Minibar that act as an aggregator by offering beer delivery via local stores. The rest of the article will go into the method of how to pull data from a website using the Python Requests library, chart and library selection based on the kind of data you are pulling, and medium- to advanced-techniques of visualization using the Bokeh library. The final files and code explained below can be found and forked here. Data Wrangling Like I said in the intro, the first challenge was capturing the data so that I could actually perform some analysis on it. Neither has an API, so I started looking at the structure of their website and network calls to see which/either could be viable. Drizly has a very odd way of injecting data directly into react components so that there’s never a simple JSON payload in the network calls (maybe for obfuscation purposes?), and it was clearly going to take a lot of time to morph it in a usable form. Switching focus to Minibar, I quickly found they not only had a standard JSON payload that was easy to grab, but had a bunch of metadata too, yeehaw! JSON in the XHR Calls Once I found this, it was just a matter of using the Requests library to pull the JSON…Or so I thought. After creating a simple request, I was met with an error message: Tell me your secrets Hm, well this is awkward. Running item_count.status_code also confirms a 401 unauthorized error, which means our response is correctly making it to the server but is getting denied due to missing some kind of credential alongside the request. Since tokens aren’t created out of thin air and the site requires no sign-in, the only logical conclusion was that it must be created for the session once a user visits the site. This prompted me to check the request headers section of XHR request referenced above, and lo and behold I came across a bearer token: Ah the missing puzzle piece Once I added in the headers parameter I was able to confirm this worked and returned data! The next challenge was to figure out how to programmatically grab and and add the bearer token to the request, since the the token would likely auto-expire in some set amount of time. My plan roughly became: Make a request to https://minibardelivery.com/ first since it does not require special authorization to access and grab the bearer token it gives me Make a request to my intended JSON target with the bearer in the header payload Loop through and flatten the data into a DataFrame The bearer turned out to be a pain to find on the main page since it wasn’t in any XHR requests, but instead included as one of the meta name tags: Sneaky sneaky So how are we going to grab something if it’s not in json? Simple, we’ll treat it like a normal web page and use Beautiful Soup! This can be done by writing a really simple function: def get_token():     url = 'https://minibardelivery.com'     r = requests.get(url)     soup = BeautifulSoup(r.text, 'html.parser')     bearer_token = soup.findAll(attrs={"name":"access-token"})[0]['content']     return bearer_token As you can see, all we did was specify to Beautiful Soup that the text should be treated like HTML, and then told it to return the contents of the access-token attribute. This saves us from doing any kind of convoluted or error-prone regex to find the token. Now that we can dynamically grab the data at any time it’s just a matter of flattening it into a DataFrame. Looking at the JSON, many beers had ‘variants’ (different prices due to pack size/store-specific sales/container types/etc.) which I also wanted to capture and contrast. Using the following code I was able to loop through all the beers based on a count variable in the initial call, add each variant as an individual line item, and then output it into a single DataFrame import requests import pandas as pd import numpy as np import time from bs4 import BeautifulSoupdef get_token():     url = 'https://minibardelivery.com'     r = requests.get(url)     soup = BeautifulSoup(r.text, 'html.parser')     bearer_token = soup.findAll(attrs={"name":"access-token"})[0]['content']     return bearer_tokenurl = '<the json url>' bearer_token = get_token() header = {'Authorization': 'bearer {}'.format(bearer_token)} item_count = round(requests.get(url+str(1), headers=header).json()['count']/20)def alc_pct(x):     if x is None:         x = np.nan     else:         x = x['value']     return xbeer_df = pd.DataFrame([]) for x in range(1,item_count+1):       time.sleep(3)     data = requests.get(url+str(x), headers=header).json()     for i in range(0, len(data['product_groupings'])):         core_data = {key: data['product_groupings'][i][key] for key in data['product_groupings'][0].keys() & {'name','type','brand'}}         core_data['hierarchy_type'] = data['product_groupings'][i]['hierarchy_type']['name']         core_data['hierarchy_subtype'] = data['product_groupings'][i]['hierarchy_subtype']['name']         core_data['alcohol_pct'] = alc_pct(next((item for item in data['product_groupings'][i]['properties'] if item["name"] == "Alcohol %"), None))         variant_df = pd.DataFrame([])         for v in range(0, len(data['product_groupings'][i]['variants'])):             variant_data = {key: data['product_groupings'][i]['variants'][v][key] for key in data['product_groupings'][i]['variants'][v].keys()                             & {'price','short_pack_size','short_volume','container_type','supplier_id'}}             core_data.update(variant_data)             variant_df = variant_df.append(core_data, ignore_index=True)         beer_df = beer_df.append(variant_df)beer_df.to_csv('beer_data.csv') Once I had ~2,000 beers in the DataFrame I used the missingno library to get a sense of how complete the data was: Yikes at alcohol_pct Turns out alcohol %, the crux of my whole experiment, was missing for a LOT of beers, about 3/5 of the dataset. Blinded by stubbornness and zeal, I did what any rational person would do in this situation — I grabbed a 6-pack from the store and spent the next several hours manually plugging in values I found searching sites like https://untappd.com/. Eventually I completed both the beer and the data entry, and was ready to move on to the next phase. Picking the Right Visualization So now that we have a nice dataset, we need to think about how we want to effectively visualize the data. The data has both quantitative and categorical dimensions, and we’re going to want to compare things like type of beer, container type, etc. against different attributes. Considering the amount of potential data points at any given point as well, scatterplots stuck out as a good choice given their ability to easily display pattern and correlation trends. I also knew there were a few different advanced interactions I wanted to perform with the visualization: I wanted it to be highly interactive since the ‘best’ value beers were likely the ones that I never want to drink anymore (looking at you King Cobra). I also wanted to filter and understand complex scenarios such as ‘best priced IPA 6 packs with at least 6% ABV’ I wanted to be able to map colors to both quantitative and categorical points in display. This would make it possible to more easily identify patterns while looking at different metrics. Since some of the data is highly cardinal as well, I wanted to assign unique colors vs. remapping 10 or 20 colors over and over. After experimenting with a few familiar simple graphing libraries I realized that this was not going to work without a highly flexible and customizable library. I ended up settling on Bokeh which not only has a huge library of pre-made charts, but also came with some great examples — particularly this move ratings one. I decided this one would suit my needs with only minor tweaks, so with that it was full-steam ahead! Getting Down and Dirty with Bokeh I’ll warn you right now, if you want to do anything beyond basic graphs with Bokeh, read the docs. I resisted at first and it resulted in me filtering through Stack Overflow and Google for hours like a lost child. Understanding the structure of where to access and update objects like glyphs and how ColumnDataSource updates data are key concepts you should try and understand without diving too much further. My second disclaimer is that some of this code is likely not efficient, but if I tried to tune/understand it anymore I would have never published this. Scaffolding Bokeh for the most part is pretty easy to understand after looking through a few examples on their site, plus I’m basically using the movie example. The idea in bullet points is: import the libraries and data, create custom metrics needed, apply any formatting / cleaning to dataset: import os import pandas as pd from bokeh.io import curdoc from bokeh.layouts import column, layout from bokeh.models import ColumnDataSource, Div, Select, Slider, LinearColorMapper, ColorBar, CategoricalColorMapper, Legend, LegendItem, CustomJS from bokeh.plotting import figure from bokeh.transform import jitter from bokeh.palettes import Reds9, Turbo256, d3 from bokeh.models.widgets import CheckboxButtonGroup, DataTable, TableColumndf = pd.read_csv('beer_data.csv') df['brand'] = ['uncat' if str(x) == 'nan' else x for x in df['brand']] df['hierarchy_type'] = ['uncat' if str(x) == 'nan' else x for x in df['hierarchy_type']] df['hierarchy_subtype'] = ['uncat' if str(x) == 'nan' else x for x in df['hierarchy_subtype']] df['total_oz'] = df['short_pack_size_num'] * df['standard vol'] df['cost_per_oz'] = round(df['price'] / df['total_oz'], 2) df['oz_of_alcohol_per_dollar'] = round(((df['total_oz'] * df['alcohol_pct']) / 100) / df['price'], 2) Create dictionaries for the axes and color selection. These will be the options users have for the x/y axis and what dimension/metric the color will be based on: axis_map = {     "Oz of Alcohol per $": "oz_of_alcohol_per_dollar",     "Cost per Oz": "cost_per_oz",     "ABV": "alcohol_pct",     "Pack Size": "short_pack_size_num",     "Volume (Oz)": "standard vol",     "Price": "price"}color_axis_map = {     "ABV": "alcohol_pct",     "Brand": "brand",     "Container Type": "container_type",     "Category": "hierarchy_type",     "Sub-Category": "hierarchy_subtype",     "Price": "price",     "Pack Size": "short_pack_size",     "Volume": "short_volume",     "Supplier": "supplier_id",     "Type": "type",     "Oz of Alcohol per $": "oz_of_alcohol_per_dollar",     "Cost per Oz": "cost_per_oz"} Create tooltip format, a description section explaining the graph, and then the widget filters we’ll be using on the side. We’ll then create a ColumnDataSource for both the graph and table: tooltips = [     ("Name", "@name"),     ("Brand", "@brand"),     ("Price $", "@price"),     ("ABV", "@alcohol_pct"),     ("Category", "@hierarchy_type"),     ("Category Sub-type", "@hierarchy_subtype")]# Create description at top of webpage desc = Div(text=open("description.html").read(), sizing_mode="stretch_width")# Create unique option lists for some of the widget filters container_options = list(df['container_type'].unique()) pack_size_options = sorted(list(df['short_pack_size'].unique())) hierarchy_options = sorted(list(df['hierarchy_type'].unique())) sub_hierarchy_options = sorted(list(df['hierarchy_subtype'].unique())) brand_options = sorted(list(df['brand'].unique()))for i in [pack_size_options, hierarchy_options, sub_hierarchy_options, brand_options]:     i.insert(0, "All")# Create widget filters min_abv = Slider(title="ABV", start=0, end=20, value=1, step=1) jitter_amt = Slider(title="Jitter", start=0, end=1.0, value=0.1, step=0.1) container_check = CheckboxButtonGroup(labels=container_options, active=[0, 2]) brand = Select(title="Brand of Beer", value="All", options=brand_options) pack_size = Select(title="Pack Size", value="All", options=pack_size_options) hierarchy = Select(title='Category', value="All", options=hierarchy_options) sub_hierarchy = Select(title='Sub-Category', value="All",                        options=sorted(sub_hierarchy_options)) y_axis = Select(title="Y Axis", options=sorted(axis_map.keys()),                 value="Oz of Alcohol per $") x_axis = Select(title="X Axis", options=sorted(axis_map.keys()), value="ABV") circle_color = Select(title="Circle Color",                       options=sorted(color_axis_map.keys()), value="Price")# Create Column Data Sources that will be used by the plot and table source = ColumnDataSource(data=dict(df)) table_source = ColumnDataSource(data=dict(df)) It seems like a lot of code but it is mainly making unique lists of columns you want for filters, assigning those lists to widgets, and setting default values for the filter. We’ll also add in a section to create a figure, glyphs, and all the styling needed for our final chart. We have both a bar and legend in here because we’ll need to toggle their visibility in order to switch between quantitative and categorical selections: p = figure(background_fill_color='black', background_fill_alpha=0.5,            border_fill_color='gray', border_fill_alpha=0.25,            plot_height=250, plot_width=500,               toolbar_location='below', tooltips=tooltips, tools="pan,box_select,wheel_zoom,reset,help",            active_drag="box_select", active_scroll='wheel_zoom'))c = p.circle(x=jitter('x', width=jitter_amt.value, range=p.x_range),              y=jitter('y', width=jitter_amt.value, range=p.y_range),              source=source, size='price', line_color=None,              fill_color={"field": color_axis_map[circle_color.value], "transform": cmap})bar = ColorBar(background_fill_color='gray', background_fill_alpha=0, color_mapper=cmap, location=(0, 0), visible=True)legend = Legend(items=[LegendItem(label=dict(field="x"), renderers=[c])],location=(10, -30), background_fill_alpha=0, visible=False)columns = [     TableColumn(field="name", title='Name'),     TableColumn(field="type", title='Type'),     TableColumn(field="container_type", title='Container Type'),     TableColumn(field="short_pack_size", title='Pack Size'),     TableColumn(field="short_volume", title='Volume'),     TableColumn(field="price", title='Price'),     TableColumn(field="alcohol_pct", title='ABV'),     TableColumn(field="cost_per_oz", title='Cost per Oz'),     TableColumn(field="oz_of_alcohol_per_dollar", title='Oz of Alcohol per $')]data_table = DataTable(source=table_source, columns=columns, selectable=False)p.add_layout(bar, "right") p.add_layout(legend, 'right') Perfect! Now that the basics are out of the way we can move to the more advanced concepts. Challenge 1 — Color Mapping One of the things I wanted to do was to map either categorical OR quantitative data to the points on the plot. I wanted the color bar to rescale on quantitative data as well, or else outliers (like the price of a keg) would mess with the color distribution of filtered data. Without going deep on the fundamental issues, my logic ended up looking like this: Define an initial color mapping based on the default variable. I chose price so I used Bokeh’s LinearColorMapper by default, but would have made this a CategoricalColorMapper had I defaulted to a categorical value Create a rescale_color function that will rescale a linear color map to the new filtered min/max upon updates Create a categorical_color_scale function that will map categorical color scales to any categorical list provided. I also added a special color scale designed to better map to highly cardinal data (like brands) Create a cat_linear_color_toggle function to determine upon updates whether the current active value in the color widget filter is categorical or quantitative Create a show_hide_legend function to toggle the visibility of the ColorBar (quantitative legend) and Legend (categorical legend) def rescale_color(cmap, df):     """Rescale the linearcolormapper based on the dataframe provided"""     cmap.low = min(df[color_axis_map[circle_color.value]])     cmap.high = max(df[color_axis_map[circle_color.value]])     return cmapdef categorical_color_scale(color_list):     """Returns a different size color scale based on color list size"""     if len(color_list) < 30:         colors = d3['Category20'][20]+d3['Category20b'][10]     else:         colors = Turbo256     return colorsdef cat_linear_color_toggle(color_col, df):     """Changes color scale based on whether color is displaying a quantitative     or categorical value upon a transformation"""     if df[color_col].dtype == 'float64' or df[color_col].dtype == 'int64':         color_mapper = rescale_color(cmap, df)     else:         cat_list = list(df[color_col].astype(str).unique())         color_mapper = CategoricalColorMapper(             factors=cat_list, palette=categorical_color_scale(cat_list))     return color_mapperdef show_hide_legend(attr, old, new):     """Used for switching to and from categorical scale"""     color_val = color_axis_map[circle_color.value]     if df[color_val].dtype in (float, int):         p.legend.visible = False         bar.visible = True     else:         p.legend.visible = True         bar.visible = False Now that we have the framework for updating our color scales/legends, we can move onto how to update everything once a user interacts with our widget filters. Challenge 2 — Updating the Graph and Filtered Data We’re going to heavily mirror the movie graph example for this, but I’ll walk through the concepts briefly. We want to create a function called select_beer() which will find all the current values for our widget filters, and then filter the dataset based on those selections: def select_beers():     """Filter data source based on widget filter input"""     container_check_val = container_check.active     abv_val = min_abv.value     brand_val = brand.value     pack_size_val = pack_size.value     hierarchy_val = hierarchy.value     sub_hierarchy_val = sub_hierarchy.valueselected = df[df['alcohol_pct'] > abv_val]     if (container_check_val != 4):         container_name_list = [container_check.labels[i] for i in container_check_val]         if len(container_name_list) == 0:             container_name_list = container_options         selected = selected[selected.container_type.isin(container_name_list)==True]     if (brand_val != "All"):         selected = selected[selected.brand.str.contains(brand_val)==True]     if (pack_size_val != "All"):         selected = selected[selected.short_pack_size.str.contains(pack_size_val)==True]     if (hierarchy_val != "All"):         selected = selected[selected.hierarchy_type.str.contains(hierarchy_val)==True]     if (sub_hierarchy_val != "All"):         selected = selected[selected.hierarchy_subtype.str.contains(sub_hierarchy_val)==True]     return selected The next thing we want to write is an update() function which will update the graph elements (such as name of axis and total # of beers selected), as well as update the ColumnDataSource which is how the data on the graph is updated. It will finally force updates on the legend/color scales by calling cat_linear_toggle and updating the legend. The final points applies to jitter to the newly filtered data: def update():     """Updates graph elements and source.data based on filtering"""     filtered_df = select_beers()     x_name = axis_map[x_axis.value]     y_name = axis_map[y_axis.value]     p.xaxis.axis_label = x_axis.value     p.yaxis.axis_label = y_axis.value     p.title.text = "%d beers selected" % len(filtered_df)     color_select = color_axis_map[circle_color.value]source.data = dict(             x=filtered_df[x_name],             y=filtered_df[y_name],             name=filtered_df["name"],             brand=filtered_df["brand"],             price=filtered_df["price"],             container_type=filtered_df["container_type"],             hierarchy_type=filtered_df["hierarchy_type"],             hierarchy_subtype=filtered_df["hierarchy_subtype"],             short_pack_size=filtered_df["short_pack_size"],             alcohol_pct=filtered_df["alcohol_pct"],             short_volume=filtered_df["short_volume"],             supplier_id=filtered_df["supplier_id"],             type=filtered_df["type"],             oz_of_alcohol_per_dollar=filtered_df["oz_of_alcohol_per_dollar"],             cost_per_oz=filtered_df["cost_per_oz"])     table_source.data = source.datatransform_scale = cat_linear_color_toggle(color_select, filtered_df)     c.glyph.fill_color = {"field": color_select, "transform": transform_scale}     p.legend.items[0].label = {'field': color_select}     if filtered_df[color_select].dtype in (float, int):         bar.color_mapper = rescale_color(cmap, filtered_df)     c.glyph.x = jitter('x', width=jitter_amt.value, range=p.x_range)     c.glyph.y = jitter('y', width=jitter_amt.value, range=p.y_range) After that’s done all we need to do is setup callbacks for all our controls. The final output is very similar to the generic bokeh in the movie example. I added a os.system(...) at the end to make it convenient to run on my local: # Determine if legend type needs to change circle_color.on_change('value', show_hide_legend)controls = [min_abv, jitter_amt, container_check, brand, pack_size, hierarchy,             sub_hierarchy, x_axis, y_axis, circle_color]for control in controls:     if (control == container_check):         container_check.on_change('active', lambda attr, old, new: update())     else:         control.on_change('value', lambda attr, old, new: update())inputs = column(*controls, width=320, height=500) inputs.sizing_mode = "fixed" l = layout([[desc], [inputs, p], [data_table]], sizing_mode="scale_both")update()  # initial load of the datacurdoc().add_root(l) curdoc().title = "Beer Plot"os.system("bokeh serve --show bokeh_scatter.py") Running this all together gave me the first visual of what we put together, not bad! Final Graph, Filters, Color Scale, and Data Table! Final Challenge — Filtering based on graph selection At this point I felt pretty happy with the output and thought I was done, but once I started examining the data I tried to highlight areas of points on the chart to filter the data table. Many data points were on top of each other, and it was difficult to examine without some way of seeing underlying selection areas. Bokeh graphs naturally handle selecting data on graphs through their default tools such as box_select, but there’s no default way to reflect this on the data table. After reading and googling more about it,I came to the unfortunate conclusion that this could not be done using the default library…ughhhhh. Luckily, Bokeh allows for use of JavaScript through the CustomJS model, and what I needed to accomplish required very little knowledge of JS. What we want to do is the following: Create a callback that executes custom javascript when a selection on the source data changes Get the indices of all the selected points If the selection > 1, create an empty dictionary, then fill with data from source.data where the index matches the indices Update table with the new dictionary # Use custom JS so that filtering on the graph affects the data table as well source.selected.js_on_change('indices', CustomJS(args=dict(source=source, table_source=table_source), code="""         var inds = cb_obj.indices;         var d1 = source.data;if(inds.length == 0){             table_source.data = d1         }         else{         d2 = {'name': [], 'type': [], 'container_type': [],               'short_pack_size': [], 'short_volume': [], 'price': [],               'alcohol_pct': [], 'cost_per_oz': [], 'oz_of_alcohol_per_dollar': []}for (var i = 0; i < inds.length; i++) {             d2['name'].push(d1['name'][inds[i]])             d2['type'].push(d1['type'][inds[i]])             d2['container_type'].push(d1['container_type'][inds[i]])             d2['short_pack_size'].push(d1['short_pack_size'][inds[i]])             d2['short_volume'].push(d1['short_volume'][inds[i]])             d2['price'].push(d1['price'][inds[i]])             d2['alcohol_pct'].push(d1['alcohol_pct'][inds[i]])             d2['cost_per_oz'].push(d1['cost_per_oz'][inds[i]])             d2['oz_of_alcohol_per_dollar'].push(d1['oz_of_alcohol_per_dollar'][inds[i]])         }         table_source.data = d2         }     """)) And there we have it! The final result should only then show the selected points reflected in the data table, similar to what you see below when I select a few data points on the graph: Selections are highlighted and Table is Dynamically Filtered Conclusion I know what you may be thinking — what about the actual beer?! So turns out there were very few surprises, the malt beverage brand 4Loko (aka battery acid in a can) was by far and away the cheapest in my area with a ‘Oz of Alcohol per $’ of $0.72, about $0.10 per oz cheaper than the next best challenger. “Alcohol %” (ABV) turns out to be the best baseline predictor for value, which you can confirm through Exploratory Data Analysis or other means. Ultimately you could probably do more like including additional zip code areas or sites into this analysis, but the excessive missing data definitely affects what you can do without some manual data cleaning. Bokeh was also really interesting to work with, but I’m not sure I’ll start with it as my first choice for graphs in the future. Maybe if I was doing data visualization for a job I would consider it, but the learning curve is pretty steep for most things people need to show with graphs. Hope this was helpful to anyone out there and feel free to reach out or comment below with questions/comments. Thanks for reading! Towards Data Science A Medium publication sharing concepts, ideas, and codes. Follow 92 Data Science Python Data Visualization Programming Data Analysis 92 claps Written by Matt Grierson Follow CTO/Head of Product @RealBlocks https://www.linkedin.com/in/matthewgrierson/ Follow Towards Data Science Follow A Medium publication sharing concepts, ideas, and codes. Follow Write the first response More From Medium More from Towards Data Science More from Towards Data Science from sklearn import * Conor Lazarou in Towards Data Science Mar 22 · 9 min read 2.5K More from Towards Data Science More from Towards Data Science Top 3 Python Functions You Don’t Know About (Probably) Dario Rade?i? in Towards Data Science Mar 14 · 4 min read 4.3K More from Towards Data Science More from Towards Data Science Don’t learn machine learning Caleb Kaiser in Towards Data Science Mar 19 · 4 min read 2.4K Discover MediumWelcome to a place where words matter. On Medium, smart voices and original ideas take center stage - with no ads in sight. Watch Make Medium yoursFollow all the topics you care about, and we’ll deliver the best stories for you to your homepage and inbox. Explore Become a memberGet unlimited access to the best stories on Medium — and support writers while you’re at it. Just $5/month. Upgrade AboutHelpLegal
